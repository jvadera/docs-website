---
title: Troubleshoot your Kafka integration
metaDescription: "Troubleshoot your Kafka integration."
redirects: 
---

## Duplicate data reporting [#duplicate-data]

For agents monitoring producers and/or consumers, and that have `Topic mode` set to `All`:, there may be a problem of duplicate data being reported. To stop the duplicate data: ensure that the [configuration option](#config) `Collect topic size` is set to false.

## Failed to get list of brokers: Unable to get broker ID from Zookeeper path [#broker-fail]

No Kafka data is reporting for the integration. You might see the following error in the logs: `[ERR] Failed to get list of brokers: unable to get broker ID from Zookeeper path /data/zookeeper_data/brokers/ids: zk: node does not exist\n"`. This is because you're trying to set a filesystem path in your `zookeeper_path` option instead of the Zookeeper namespace.

Typically you can just leave `zookeeper_path` commented out and the default will work, or you can explore the Zookeeper namespace via something like `zookeeper-shell` to find where the information on brokers is located.

## Unable to see Kafka metrics [#kafka-metrics]

You are facing an issue where you aren't able to see Kafka Metrics using New Relic metric explorer. 

* The New Relic Java agent automatically collects data from Kafka's Java clients library. Because Kafka is a high-performance messaging system that generates a lot of data, you can customize the agent for your app's specific throughput and use cases.
* If you are still missing these message broker metrics -  you may confirm if those messages are indeed generated from your Kafka client. The simplest way to see the available metrics is to kick start Jconsole and point it at a running kafka client to see if the metrics are enabled for the message broker.
* If you still face the issue and you aren't able to achieve the expected results, you may use New Relic Kafka on-host integration that reports metrics and configuration data from your Kafka service.

## Integration logs errors `zk: node not found` [#logs-error-node]

Ensure that `zookeeper_path` is set correctly in the [configuration file](#config).

## Kafka error: `zk: node does not exist` [#node-doesnt-exist]

The Kafka integration is connecting to the instance but not collecting data.
The error in the logs is: `/kafka-root/brokers/ids: zk: node does not exist`

This occurs because you're trying to set a filesystem path in your `zookeeper_path option` instead of the Zookeeper namespace. It indicates that the broker id list can't be found at the zookeeper_path you have set in the config. 

Typically, you can just leave `zookeeper_path` commented out in the configuration file and the default will work, or you can explore the Zookeeper namespace via something like `zookeeper-shell` to find where the information on brokers is located.

## JMX connection errors [#jmx-connection]

    The Kafka integration uses a JMX helper tool called `nrjmx` to retrieve JMX metrics from brokers, consumers, and producers. JMX needs to be enabled and configured on all brokers in the cluster. Also, firewalls need to be tuned to allow connections from the host running the integration to the brokers over the JMX port.

    To check whether JMX is correctly configured, run the following command for each broker from the machine running the Kafka integration. Replace the `PORT`, `USERNAME`, and `PASSWORD` variables with the corresponding JMX settings for the brokers:

    ```shell
    echo "*:*" | nrjmx -hostname MY_HOSTNAME -port MY_PORT -v -username MY_USERNAME -password MY_PASSWORD
    ```

    The command should generate the output showing a long series of metrics without any errors.

## Kerberos authentication failing [#kerberos-fail]

    The integration might show an error like the following:

    ```shell
    KRB Error: (6) KDC_ERR_C_PRINCIPAL_UNKNOWN Client not found in Kerberos database
    ```

    Check the keytab with kinit command. Replace the highlighted fields with your values:

    ```shell
    $ kinit -k -t KEY_TAB_PATH USERNAME
    ```

    If the username/keytab combination is correct, the command above should finish without printing any errors.

    Check the realm using klist command:

    ```shell
    $ klist |grep "Default principal:"
    ```

    You should see something like this:

    ```shell
    Default principal: johndoe@a_realm_name
    ```

    Check that the printed user name and realm match the `sasl_gssapi_realm` and `sasl_gssapi_username` parameters in the integration configuration.

## Kafka lag units [#lag-units]

You want to know the  consumer.lag metric for Kafka offset.

The `kafka lag` is not a unit of time, rather the calculated difference between a consumer’s current log offset and a producer’s current log offset. It’s the number of messages the consumer is behind of the producer.

The `consumer.lag` is calculated as -The difference between a broker's high water mark and the consumer's offset `(consumer.hwm - consumer.offset)`.
